{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f17b3fdb",
   "metadata": {},
   "source": [
    "# ğŸ”ï¸ Glacier Hack 2025 - Kaggle Training Notebook\n",
    "\n",
    "This notebook trains an optimized UNet model for glacier segmentation using advanced techniques to achieve **70-75% MCC** performance.\n",
    "\n",
    "## Key Features:\n",
    "- âœ… **Custom UNet Architecture** with proven stability\n",
    "- âœ… **TverskyLoss** optimized for imbalanced glacier data\n",
    "- âœ… **Global Normalization** for consistent training\n",
    "- âœ… **Advanced Training** with AMP, SWA, threshold sweeping\n",
    "- âœ… **Kaggle-Compatible** file saving and submission prep\n",
    "\n",
    "Expected training time: **2-3 hours** | Target MCC: **70-75%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Initial Setup and GPU Check\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"ğŸ”¥ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ¯ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected - training will be very slow!\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/kaggle/working')\n",
    "print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Show available space\n",
    "result = subprocess.run(['df', '-h', '/kaggle/working'], capture_output=True, text=True)\n",
    "print(f\"ğŸ’½ Available space:\\n{result.stdout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Clone Repository and Download Data\n",
    "print(\"ğŸ”„ Cloning repository...\")\n",
    "!git clone https://github.com/observer04/glacier-hack.git\n",
    "os.chdir('/kaggle/working/glacier-hack')\n",
    "\n",
    "print(\"ğŸ“¥ Downloading training data...\")\n",
    "!wget -q https://www.glacier-hack.in/train.zip\n",
    "!unzip -q train.zip -d ./\n",
    "!mv ./Train/Train/* ./Train/\n",
    "!rmdir ./Train/Train\n",
    "\n",
    "# Verify data structure\n",
    "print(\"âœ… Data structure verification:\")\n",
    "train_files = os.listdir('Train/')\n",
    "print(f\"ğŸ“Š Total training files: {len(train_files)}\")\n",
    "print(f\"ğŸ“‹ Sample files: {train_files[:5]}\")\n",
    "\n",
    "# Clean up zip file to save space\n",
    "!rm train.zip\n",
    "print(\"ğŸ§¹ Cleaned up zip file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ Install Dependencies\n",
    "print(\"ğŸ“‹ Installing required packages...\")\n",
    "!pip install -q tqdm scikit-learn matplotlib pillow tifffile\n",
    "\n",
    "# Import and verify installation\n",
    "import tqdm\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tifffile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")\n",
    "\n",
    "# Verify we can load the training modules\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/glacier-hack')\n",
    "\n",
    "try:\n",
    "    from data_utils import GlacierDataset, compute_global_stats\n",
    "    from models import UNet\n",
    "    from train_utils import TverskyLoss\n",
    "    print(\"âœ… All custom modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"ğŸ” Available files:\")\n",
    "    !ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Start Optimized Training (UNet + Tversky)\n",
    "print(\"ğŸš€ Starting optimized training...\")\n",
    "print(\"ğŸ“‹ Configuration:\")\n",
    "print(\"   â€¢ Model: UNet (proven stable architecture)\")\n",
    "print(\"   â€¢ Loss: TverskyLoss (Î±=0.7, Î²=0.3 for imbalanced data)\")\n",
    "print(\"   â€¢ Batch Size: 2 (memory optimized)\")\n",
    "print(\"   â€¢ Epochs: 80\")\n",
    "print(\"   â€¢ Features: AMP, SWA, Threshold Sweep, Global Normalization\")\n",
    "print(\"   â€¢ Expected MCC: 70-75%\")\n",
    "print(\"   â€¢ Training Time: ~2-3 hours\")\n",
    "print()\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('/kaggle/working/models', exist_ok=True)\n",
    "\n",
    "# Run the training\n",
    "!python train_model.py \\\n",
    "    --model_type unet \\\n",
    "    --loss_type tversky \\\n",
    "    --batch_size 2 \\\n",
    "    --epochs 80 \\\n",
    "    --lr 0.001 \\\n",
    "    --save_dir /kaggle/working/models \\\n",
    "    --use_amp \\\n",
    "    --use_swa \\\n",
    "    --threshold_sweep \\\n",
    "    --scheduler plateau \\\n",
    "    --normalize_type global \\\n",
    "    --data_dir Train \\\n",
    "    --patience 15 \\\n",
    "    --gradient_accumulation_steps 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e86e11",
   "metadata": {},
   "source": [
    "## ğŸ“Š Monitor Training Progress\n",
    "\n",
    "**Run the cell below periodically while training to monitor progress:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Monitor Training Progress\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "def monitor_training():\n",
    "    \"\"\"Monitor training progress by reading logs\"\"\"\n",
    "    log_files = glob.glob('/kaggle/working/models/*/training.log')\n",
    "    if log_files:\n",
    "        latest_log = max(log_files, key=os.path.getctime)\n",
    "        print(f\"ğŸ“Š Monitoring: {latest_log}\")\n",
    "        print(\"ğŸ“‹ Last 20 lines of training log:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        with open(latest_log, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[-20:]:\n",
    "                print(line.strip())\n",
    "    else:\n",
    "        print(\"â³ No training logs found yet...\")\n",
    "        print(\"ğŸ” Available directories:\")\n",
    "        dirs = glob.glob('/kaggle/working/models/*')\n",
    "        for d in dirs:\n",
    "            print(f\"   ğŸ“ {d}\")\n",
    "\n",
    "def show_gpu_usage():\n",
    "    \"\"\"Show current GPU usage\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        print(\"ğŸ–¥ï¸ GPU Status:\")\n",
    "        print(result.stdout)\n",
    "    except:\n",
    "        print(\"âŒ Could not get GPU status\")\n",
    "\n",
    "# Monitor training\n",
    "monitor_training()\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "show_gpu_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bfde14",
   "metadata": {},
   "source": [
    "## ğŸ Prepare Submission Files\n",
    "\n",
    "**Run this after training completes to prepare your competition submission:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3eb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ Prepare Final Submission Files\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "print(\"ğŸ” Searching for trained models...\")\n",
    "\n",
    "# Find the best model\n",
    "model_dirs = glob.glob('/kaggle/working/models/*')\n",
    "if model_dirs:\n",
    "    latest_model_dir = max(model_dirs, key=os.path.getctime)\n",
    "    print(f\"ğŸ“ Latest model directory: {latest_model_dir}\")\n",
    "    \n",
    "    # Create submission directory\n",
    "    submission_dir = '/kaggle/working/submission'\n",
    "    os.makedirs(submission_dir, exist_ok=True)\n",
    "    \n",
    "    # Find and copy best model\n",
    "    best_model_files = glob.glob(f'{latest_model_dir}/best_model.pth')\n",
    "    if best_model_files:\n",
    "        # Copy model as model.pth (competition requirement)\n",
    "        shutil.copy(best_model_files[0], f'{submission_dir}/model.pth')\n",
    "        print(\"âœ… Model copied as model.pth\")\n",
    "        \n",
    "        # Copy solution.py\n",
    "        shutil.copy('/kaggle/working/glacier-hack/solution.py', f'{submission_dir}/')\n",
    "        print(\"âœ… Solution.py copied\")\n",
    "        \n",
    "        # Show final files\n",
    "        print(\"\\nğŸ¯ SUBMISSION FILES READY:\")\n",
    "        print(\"=\" * 40)\n",
    "        files = os.listdir(submission_dir)\n",
    "        for file in files:\n",
    "            size = os.path.getsize(f'{submission_dir}/{file}') / (1024*1024)  # MB\n",
    "            print(f\"ğŸ“„ {file} ({size:.1f} MB)\")\n",
    "        \n",
    "        # Copy training summary\n",
    "        log_files = glob.glob(f'{latest_model_dir}/training.log')\n",
    "        if log_files:\n",
    "            shutil.copy(log_files[0], f'{submission_dir}/training_log.txt')\n",
    "            \n",
    "            # Show final training results\n",
    "            print(\"\\nğŸ“Š FINAL TRAINING RESULTS:\")\n",
    "            print(\"=\" * 40)\n",
    "            with open(log_files[0], 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines[-10:]:\n",
    "                    if 'Best' in line or 'MCC' in line:\n",
    "                        print(f\"ğŸ† {line.strip()}\")\n",
    "        \n",
    "        print(f\"\\nâœ… All files ready in: {submission_dir}\")\n",
    "        print(\"ğŸ’¡ Download these files from Kaggle's output section!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No best_model.pth found!\")\n",
    "        print(\"ğŸ” Available files in model directory:\")\n",
    "        available_files = glob.glob(f'{latest_model_dir}/*')\n",
    "        for file in available_files:\n",
    "            print(f\"   ğŸ“„ {os.path.basename(file)}\")\n",
    "else:\n",
    "    print(\"âŒ No model directories found!\")\n",
    "    print(\"ğŸ” Available directories:\")\n",
    "    dirs = os.listdir('/kaggle/working/models')\n",
    "    for d in dirs:\n",
    "        print(f\"   ğŸ“ {d}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
